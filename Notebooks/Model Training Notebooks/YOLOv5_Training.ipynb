{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrsaDfdVHzxt"
   },
   "source": [
    "# MDP - Training with YOLOv5\n",
    "\n",
    "This notebook is just a summarized, unbranded version of the one provided by [Ultralytics](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNveqeA1KXGy"
   },
   "source": [
    "# Step 1: Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kTvDNSILZoN9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'yolov5'\n",
      "C:\\Users\\DELL G15\\Desktop\\SCHOOL\\MDP\\CZ3004-SC2079-MDP-ImageRecognition-main\\Notebooks\\Model Training Notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: Too many arguments.\n",
      "\n",
      "usage: git clone [<options>] [--] <repo> [<dir>]\n",
      "\n",
      "    -v, --[no-]verbose    be more verbose\n",
      "    -q, --[no-]quiet      be more quiet\n",
      "    --[no-]progress       force progress reporting\n",
      "    --[no-]reject-shallow don't clone shallow repository\n",
      "    -n, --no-checkout     don't create a checkout\n",
      "    --checkout            opposite of --no-checkout\n",
      "    --[no-]bare           create a bare repository\n",
      "    --[no-]mirror         create a mirror repository (implies --bare)\n",
      "    -l, --[no-]local      to clone from a local repository\n",
      "    --no-hardlinks        don't use local hardlinks, always copy\n",
      "    --hardlinks           opposite of --no-hardlinks\n",
      "    -s, --[no-]shared     setup as shared repository\n",
      "    --[no-]recurse-submodules[=<pathspec>]\n",
      "                          initialize submodules in the clone\n",
      "    --[no-]recursive ...  alias of --recurse-submodules\n",
      "    -j, --[no-]jobs <n>   number of submodules cloned in parallel\n",
      "    --[no-]template <template-directory>\n",
      "                          directory from which templates will be used\n",
      "    --[no-]reference <repo>\n",
      "                          reference repository\n",
      "    --[no-]reference-if-able <repo>\n",
      "                          reference repository\n",
      "    --[no-]dissociate     use --reference only while cloning\n",
      "    -o, --[no-]origin <name>\n",
      "                          use <name> instead of 'origin' to track upstream\n",
      "    -b, --[no-]branch <branch>\n",
      "                          checkout <branch> instead of the remote's HEAD\n",
      "    -u, --[no-]upload-pack <path>\n",
      "                          path to git-upload-pack on the remote\n",
      "    --[no-]depth <depth>  create a shallow clone of that depth\n",
      "    --[no-]shallow-since <time>\n",
      "                          create a shallow clone since a specific time\n",
      "    --[no-]shallow-exclude <revision>\n",
      "                          deepen history of shallow clone, excluding rev\n",
      "    --[no-]single-branch  clone only one branch, HEAD or --branch\n",
      "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
      "    --tags                opposite of --no-tags\n",
      "    --[no-]shallow-submodules\n",
      "                          any cloned submodules will be shallow\n",
      "    --[no-]separate-git-dir <gitdir>\n",
      "                          separate git dir from working tree\n",
      "    --[no-]ref-format <format>\n",
      "                          specify the reference format to use\n",
      "    -c, --[no-]config <key=value>\n",
      "                          set config inside the new repository\n",
      "    --[no-]server-option <server-specific>\n",
      "                          option to transmit\n",
      "    -4, --ipv4            use IPv4 addresses only\n",
      "    -6, --ipv6            use IPv6 addresses only\n",
      "    --[no-]filter <args>  object filtering\n",
      "    --[no-]also-filter-submodules\n",
      "                          apply partial clone filters to submodules\n",
      "    --[no-]remote-submodules\n",
      "                          any cloned submodules will use their remote-tracking branch\n",
      "    --[no-]sparse         initialize sparse-checkout file to include only files at root\n",
      "    --[no-]bundle-uri <uri>\n",
      "                          a URI for downloading bundles before fetching from origin remote\n",
      "\n",
      "C:\\Users\\DELL G15\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Setup complete. Using torch 2.5.1+cpu (CPU)\n"
     ]
    }
   ],
   "source": [
    "#clone YOLOv5 and \n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt # install dependencies\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zP6USLgz2f0r"
   },
   "source": [
    "# Step 2: Assemble Our Dataset\n",
    "\n",
    "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2jjT5uIHo6l5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# set up environment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET_DIRECTORY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZUg_Enn1dxc",
    "outputId": "109fdc67-3746-4f87-9c51-625c4f0c300a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-9bqAZsKoQ9"
   },
   "source": [
    "Copy over the pretrained model if any, to use as the starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x7hSiABY1mX7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cp \"/content/drive/MyDrive/YOLOv5_FullPretraining.pt\" \"best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYrPwOAmKr--"
   },
   "source": [
    "Copy over the dataset and extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7DDRxnj1sFe"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/Week8.zip\" \"Week8.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OophzbZd1tmx"
   },
   "outputs": [],
   "source": [
    "!unzip -q Week8.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7yAi9hd-T4B"
   },
   "source": [
    "# Step 3: Train Our Custom YOLOv5 model\n",
    "\n",
    "Here, we are able to pass a number of arguments:\n",
    "- **img:** define input image size\n",
    "- **batch:** determine batch size\n",
    "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
    "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
    "- **cache:** cache images for faster training\n",
    "- **hyp:** hyperparameters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aoEH4Ct2jbs",
    "outputId": "9b15222d-c0ae-4217-f48c-83eb76e919fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 23 14:23:19 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.36                 Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   58C    P0             39W /  130W |       0MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9SQ0s0EJ97g"
   },
   "source": [
    "Here, run `!python train.py --img 416 --batch 128 --epochs 150 --data Week8/datav5.yaml --weights best.pt --cache` first, then get the `hyp.yaml` and set flip_lr to 0, as we do not want to flip horizontally to not confuse the left and right arrows. Then, place the `hyp.yaml` back into the appropriate location and execute the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eaFNnxLJbq4J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\\\Users\\\\DELL G15\\\\Desktop\\\\SCHOOL\\\\MDP\\\\CZ3004-SC2079-MDP-ImageRecognition-main\\\\Notebooks\\\\Model Training Notebooks\\\\train.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 416 --batch 128 --epochs 150 --data Week8/datav5.yaml --weights best.pt --cache --hyp hyp.yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtmS7_TXFsT3"
   },
   "source": [
    "#Run Inference  With Trained Weights\n",
    "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TWjjiBcic3Vz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\\\Users\\\\DELL G15\\\\Desktop\\\\SCHOOL\\\\MDP\\\\CZ3004-SC2079-MDP-ImageRecognition-main\\\\Notebooks\\\\Model Training Notebooks\\\\detect.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7iiObB2WCMh6",
    "outputId": "5c2c1e8a-a857-4284-d627-42f99724c9e8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#export your model's weights for future use\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      3\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./runs/train/exp/weights/best.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#export your model's weights for future use\n",
    "from google.colab import files\n",
    "files.download('./runs/train/exp/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNn-obvOGITm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
